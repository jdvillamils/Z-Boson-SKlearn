{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5462d3bf",
   "metadata": {},
   "source": [
    "# Analysis Z Boson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4667148d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot3\n",
    "import pandas as pd \n",
    "import time \n",
    "import math \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.ticker import AutoMinorLocator \n",
    "\n",
    "#Local information file\n",
    "import infofile "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34472b2",
   "metadata": {},
   "source": [
    "List with all the sampels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "66c1dc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "    samples = {\n",
    "    \n",
    "    'Zsignal' : {\n",
    "    'list' : [#'Zee',\n",
    "             'Zmumu',\n",
    "             #'Ztautau'\n",
    "             ]\n",
    "   },\n",
    "    \n",
    "    'diboson' : {\n",
    "        'list' : ['ZqqZll', \n",
    "                  #'WqqZll',\n",
    "                  #'WpqqWmlv', \n",
    "                  #'WplvWmqq',\n",
    "                  #'WlvZqq',\n",
    "                  'llll',\n",
    "                  'lllv',\n",
    "                  #'llvv',\n",
    "                  #'lvvv'\n",
    "        ]},\n",
    "    \n",
    "    'single_top' : {\n",
    "        'list' : ['single_top_tchan',\n",
    "                  #'single_antitop_tchan',\n",
    "                  #'single_top_schan',\n",
    "                  #'single_antitop_schan',\n",
    "                  #'single_top_wtchan',\n",
    "                  #'single_antitop_wtchan'\n",
    "                 ]\n",
    "    },\n",
    "    \n",
    "    #'WJets' : {\n",
    "    #'list' : ['Wplusenu',\n",
    "             #'Wplusmunu',\n",
    "             #'Wplustaunu',\n",
    "             #'Wminusenu',\n",
    "             #'Wminusmunu',\n",
    "             #'Wminustaunu'\n",
    "     #        ]\n",
    "     #        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cfb905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lumi = 10 # data_A+B+C+D\n",
    "\n",
    "fraction = 0.07 # fraction for not running the whole data (running it all make the script crash)\n",
    "\n",
    "tuple_path = \"https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/2lep/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92d1acd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_files():\n",
    "\n",
    "    data = {} \n",
    "    for s in samples: \n",
    "        print('Processing '+s+' samples') \n",
    "        frames = [] \n",
    "        for val in samples[s]['list']: \n",
    "            if s == 'data': prefix = \"Data/\" # Data prefix\n",
    "            else: # MC prefix\n",
    "                prefix = \"MC/mc_\"+str(infofile.infos[val][\"DSID\"])+\".\"\n",
    "            fileString = tuple_path+prefix+val+\".2lep.root\" \n",
    "            temp = read_file(fileString,val) \n",
    "            frames.append(temp) \n",
    "        data[s] = pd.concat(frames) \n",
    "    \n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ba1def3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xsec_weight(sample):\n",
    "    info = infofile.infos[sample] \n",
    "    xsec_weight = (lumi*1000*info[\"xsec\"])/(info[\"sumw\"]*info[\"red_eff\"]) \n",
    "    return xsec_weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f1d517c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_weight(xsec_weight, mcWeight, scaleFactor_PILEUP,\n",
    "                scaleFactor_ELE, scaleFactor_MUON, \n",
    "                scaleFactor_LepTRIGGER ):\n",
    "    return xsec_weight*mcWeight*scaleFactor_PILEUP*scaleFactor_ELE*scaleFactor_MUON*scaleFactor_LepTRIGGER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40716206",
   "metadata": {},
   "source": [
    "## Definition of the cut functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69081c7c",
   "metadata": {},
   "source": [
    "Check satisfied triggers E and M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ffa5043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_trig(trige,trigm):\n",
    "    l=1\n",
    "    if trige==1 or trigm==1:\n",
    "        l=0\n",
    "    return(l != 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e9c8342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def just_two_leptons(lep_n):\n",
    "    return lep_n != 2 #throw away when the number lepton is different of 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681ec6bc",
   "metadata": {},
   "source": [
    "Find two good leptons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "663d3e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_good_leptons(lep_pt,lep_ptcone30,lep_etcone20,lep_type,lep_eta,lep_trackd0pvunbiased,lep_tracksigd0pvunbiased,lep_z0):\n",
    "    if lep_pt[0] < 25000 : return True  #pt required to be bigger than 25GeV\n",
    "    #isolated leptons (good when <0.15)\n",
    "    if lep_ptcone30[0]/lep_pt[0] > 0.15: return True\n",
    "    if lep_ptcone30[1]/lep_pt[1] > 0.15: return True\n",
    "    if lep_etcone20[0]/lep_pt[0] > 0.15: return True\n",
    "    if lep_etcone20[1]/lep_pt[1] > 0.15: return True\n",
    "    #electron in fiducial region\n",
    "    if lep_type[0]==11 and (abs(lep_eta[0]>2.47) or abs(lep_eta[0]>1.37)) : return True\n",
    "    if lep_type[1]==11 and (abs(lep_eta[1]>2.47) or abs(lep_eta[1]>1.37)) : return True\n",
    "    if lep_type[0]==11 and lep_trackd0pvunbiased[0]/lep_tracksigd0pvunbiased[0] > 5 : return True\n",
    "    if lep_type[1]==11 and lep_trackd0pvunbiased[1]/lep_tracksigd0pvunbiased[1] > 5 : return True\n",
    "    #muon\n",
    "    if lep_type[0]==13 and abs(lep_eta[0]>2.5): return True\n",
    "    if lep_type[1]==13 and abs(lep_eta[1]>2.5): return True\n",
    "    if lep_type[0]==13 and lep_trackd0pvunbiased[0]/lep_tracksigd0pvunbiased[0] > 3 : return True\n",
    "    if lep_type[1]==13 and lep_trackd0pvunbiased[1]/lep_tracksigd0pvunbiased[1] > 3 : return True\n",
    "    #Longitudinal impact parameter\n",
    "    theta0 = 2*np.arctan(np.exp(-lep_eta[0]))\n",
    "    theta1 = 2*np.arctan(np.exp(-lep_eta[1]))\n",
    "    if abs(lep_z0[0]*np.sin(theta0))>0.5: return True\n",
    "    if abs(lep_z0[1]*np.sin(theta1))>0.5: return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55530357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opposite_charge(lep_charge):\n",
    "    return lep_charge[0]*lep_charge[1] > 0 #throw away when > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a98e3a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_flavour(lep_type):\n",
    "    return lep_type[0]!=lep_type[1] #throw away when different flavour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d01d014",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Invariant mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01d3197b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_inv_mass_pair(pt_1,eta_1,phi_1,E_1,pt_2,eta_2,phi_2,E_2): # pt,eta,phi,energy of 2 objects\n",
    "    px_1 = pt_1*np.cos(phi_1) # x-momentum of object 1\n",
    "    py_1 = pt_1*np.sin(phi_1) # y-momentum of object 1\n",
    "    pz_1 = pt_1*np.sinh(eta_1) # z-momentum of object 1\n",
    "    px_2 = pt_2*np.cos(phi_2) # x-momentum of object 2\n",
    "    py_2 = pt_2*np.sin(phi_2) # y-momentum of object 2\n",
    "    pz_2 = pt_2*np.sinh(eta_2) # z-momentum of object 2\n",
    "    sumpx = px_1 + px_2 # x-momentum of combined system\n",
    "    sumpy = py_1 + py_2 # y-momentum of combined system\n",
    "    sumpz = pz_1 + pz_2 # z-momentum of combined system\n",
    "    sump = np.sqrt(sumpx**2 + sumpy**2 + sumpz**2) # total momentum of combined system\n",
    "    sumE = E_1 + E_2 # total energy of combined system\n",
    "    return np.sqrt(sumE**2 - sump**2)/1000 # /1000 to go from MeV to GeV\n",
    "\n",
    "# calculate dilepton invariant mass\n",
    "def calc_mll(lep_pt,lep_eta,lep_phi,lep_E): # lepton pt,eta,phi,energy\n",
    "    return calc_inv_mass_pair(lep_pt[0],lep_eta[0],lep_phi[0],lep_E[0],lep_pt[1],lep_eta[1],lep_phi[1],lep_E[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67b64481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mass_selection(invmass):\n",
    "    return abs(invmass-91.18) > 25 #we need when the difference is lesser than 25 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdcc8bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_jets(jet_n):\n",
    "    return jet_n != 0 #We need no jets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce1f765",
   "metadata": {},
   "source": [
    "Determine the leading lepton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b89b814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lead_lep(lep_pt):\n",
    "    if lep_pt[0]>lep_pt[1]:\n",
    "        return lep_pt[0]/1000\n",
    "    else:\n",
    "        return lep_pt[1]/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ba879d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  sublead_lep(lep_pt):\n",
    "    if lep_pt[0]>lep_pt[1]:\n",
    "        return lep_pt[1]/1000\n",
    "    else:\n",
    "        return lep_pt[0]/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d06e22",
   "metadata": {},
   "source": [
    "### Read section "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85f9cac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path,sample):\n",
    "    start = time.time() # start the clock\n",
    "    print(\"\\tProcessing: \"+sample) # print which sample is being processed\n",
    "    data_all = pd.DataFrame() # define empty pandas DataFrame to hold all data for this sample\n",
    "    tree = uproot3.open(path)[\"mini\"] # open the tree called mini\n",
    "    numevents = uproot3.numentries(path, \"mini\") # number of events\n",
    "    if 'data' not in sample: xsec_weight = get_xsec_weight(sample) # get cross-section weight\n",
    "    for data in tree.iterate(['lep_charge','lep_type','lep_pt', 'lep_eta', 'lep_ptcone30',\n",
    "                              'lep_etcone20', 'lep_trackd0pvunbiased', 'lep_tracksigd0pvunbiased', 'lep_z0', 'jet_n', \n",
    "                              'trigE', 'trigM', 'lep_n', 'lep_charge', 'lep_phi', 'lep_E',\n",
    "                              'mcWeight','scaleFactor_PILEUP',\n",
    "                              'scaleFactor_ELE','scaleFactor_MUON',\n",
    "                              'scaleFactor_LepTRIGGER'\n",
    "                             ],\n",
    "                             outputtype=pd.DataFrame, # choose output type as pandas DataFrame\n",
    "                             entrystop=numevents*fraction): # process up to numevents*fraction\n",
    "\n",
    "        nIn = len(data.index) # number of events in this batch\n",
    "\n",
    "\n",
    "        # cut on triggers\n",
    "        fail = data[ np.vectorize(cut_trig)(data.trigE,data.trigM)].index\n",
    "        data.drop(fail, inplace=True)\n",
    "        \n",
    "        # cut on lepton number\n",
    "        fail = data[ np.vectorize(just_two_leptons)(data.lep_n)].index\n",
    "        data.drop(fail, inplace=True)\n",
    "        \n",
    "        # Keep just good leptons\n",
    "        fail = data[ np.vectorize(find_good_leptons)(data.lep_pt,data.lep_ptcone30,data.lep_etcone20,data.lep_type,data.lep_eta,data.lep_trackd0pvunbiased,data.lep_tracksigd0pvunbiased,data.lep_z0)].index\n",
    "        data.drop(fail, inplace=True)\n",
    "        \n",
    "        #Check SFOS\n",
    "        fail = data[ np.vectorize(opposite_charge)(data.lep_charge)].index\n",
    "        data.drop(fail, inplace=True)\n",
    "        fail = data[ np.vectorize(same_flavour)(data.lep_type)].index\n",
    "        data.drop(fail, inplace=True)\n",
    "        \n",
    "        #Check no jets\n",
    "        fail = data[ np.vectorize(check_jets)(data.jet_n)].index\n",
    "        data.drop(fail, inplace=True)\n",
    "        \n",
    "        #Then, we save tha value of the invariant mass\n",
    "        data['mll'] = np.vectorize(calc_mll)(data.lep_pt, data.lep_eta, data.lep_phi, data.lep_E)#Calc invariant mass\n",
    "        fail = data[ np.vectorize(mass_selection)(data.mll)].index\n",
    "        data.drop(fail, inplace=True)#just keep good masses\n",
    "        data['lead_pt'] = np.vectorize(lead_lep)(data.lep_pt)#save pt of leading lepton\n",
    "        data['sublead_pt'] = np.vectorize(sublead_lep)(data.lep_pt)#save pt subleading lepton\n",
    "        data['totalWeight'] = np.vectorize(calc_weight)(xsec_weight,\n",
    "                                                            data.mcWeight,\n",
    "                                                            data.scaleFactor_PILEUP,\n",
    "                                                            data.scaleFactor_ELE,\n",
    "                                                            data.scaleFactor_MUON,\n",
    "                                                            data.scaleFactor_LepTRIGGER)\n",
    "                \n",
    "\n",
    "        \n",
    "        #Now we're going to save relevant information in root files, for being precessed by TMVA\n",
    "        \n",
    "\n",
    "        nOut = len(data.index) # number of events passing cuts in this batch\n",
    "        data_all = data_all.append(data) # append dataframe from this batch to the dataframe for the whole sample\n",
    "        elapsed = time.time() - start # time taken to process\n",
    "        print(\"\\t\\t nIn: \"+str(nIn)+\",\\t nOut: \\t\"+str(nOut)+\"\\t in \"+str(round(elapsed,1))+\"s\") # events before and after\n",
    "    \n",
    "    return data_all # return dataframe containing events passing all cuts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89b1010",
   "metadata": {},
   "source": [
    "Create the destination root file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7fee0d",
   "metadata": {},
   "source": [
    "roof = uproot3.recreate(\"mcdata1.root\")\n",
    "roof"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a0a221",
   "metadata": {},
   "source": [
    "roof[\"signal\"] = uproot3.newtree({\"mll\": np.float32, \"lead_lep\": np.float32, \"sublead_lep\": np.float32, \"weight\": np.float32})\n",
    "roof[\"background\"] = uproot3.newtree({\"mll\": np.float32, \"lead_lep\": np.float32, \"sublead_lep\": np.float32, \"weight\": np.float32})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8429474a",
   "metadata": {},
   "source": [
    "start the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bad4237e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Zsignal samples\n",
      "\tProcessing: Zmumu\n",
      "\t\t nIn: 145063,\t nOut: \t84500\t in 46.0s\n",
      "\t\t nIn: 145063,\t nOut: \t84696\t in 74.5s\n",
      "\t\t nIn: 145063,\t nOut: \t84475\t in 110.3s\n",
      "\t\t nIn: 145063,\t nOut: \t84734\t in 140.3s\n",
      "\t\t nIn: 145063,\t nOut: \t84602\t in 176.8s\n",
      "\t\t nIn: 145063,\t nOut: \t84772\t in 218.7s\n",
      "\t\t nIn: 145063,\t nOut: \t84408\t in 250.6s\n",
      "\t\t nIn: 145063,\t nOut: \t84950\t in 288.3s\n",
      "\t\t nIn: 145063,\t nOut: \t84658\t in 321.0s\n",
      "\t\t nIn: 145063,\t nOut: \t84483\t in 358.4s\n",
      "\t\t nIn: 97967,\t nOut: \t56874\t in 381.9s\n",
      "Processing diboson samples\n",
      "\tProcessing: ZqqZll\n",
      "\t\t nIn: 98220,\t nOut: \t4012\t in 24.3s\n",
      "\tProcessing: llll\n",
      "\t\t nIn: 106415,\t nOut: \t6667\t in 27.4s\n",
      "\t\t nIn: 106415,\t nOut: \t6593\t in 36.7s\n",
      "\t\t nIn: 85798,\t nOut: \t5309\t in 47.5s\n",
      "\tProcessing: lllv\n",
      "\t\t nIn: 106380,\t nOut: \t2729\t in 52.8s\n",
      "\t\t nIn: 106380,\t nOut: \t2762\t in 70.0s\n",
      "\t\t nIn: 52665,\t nOut: \t1347\t in 78.9s\n",
      "Processing single_top samples\n",
      "\tProcessing: single_top_tchan\n",
      "\t\t nIn: 2579,\t nOut: \t8\t in 1.2s\n",
      "Time taken: 537.8s\n"
     ]
    }
   ],
   "source": [
    "start = time.time() # time at start of whole processing\n",
    "data = get_data_from_files() # process all files\n",
    "elapsed = time.time() - start # time after whole processing\n",
    "print(\"Time taken: \"+str(round(elapsed,1))+\"s\") # print total time taken to process every file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa21dfa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Zsignal':              mll    lead_pt  sublead_pt\n",
       " entry                                  \n",
       " 0      96.437902  59.853551   36.053645\n",
       " 2      89.374513  31.101098   29.755781\n",
       " 3      66.346769  39.272441   27.427332\n",
       " 7      83.501239  44.986766   27.580324\n",
       " 8      86.343173  49.866738   32.010543\n",
       " ...          ...        ...         ...\n",
       " 12390  72.525405  41.659898   31.402355\n",
       " 12397  80.832368  35.258590   34.822457\n",
       " 12439  68.375047  37.293613   29.522963\n",
       " 12489  76.803232  48.588219   29.210387\n",
       " 12540  74.904122  39.423984   35.579734\n",
       " \n",
       " [903491 rows x 3 columns],\n",
       " 'diboson':               mll    lead_pt  sublead_pt\n",
       " entry                                   \n",
       " 10      81.861584  34.424352   21.918508\n",
       " 20      87.515479  55.953770   34.255965\n",
       " 37      76.861029  44.088988   28.396139\n",
       " 52      89.942979  46.832094   44.034062\n",
       " 66      67.186258  36.522566   30.805287\n",
       " ...           ...        ...         ...\n",
       " 298583  85.816306  34.103008   30.343885\n",
       " 298606  99.553750  43.745988   41.560977\n",
       " 298609  69.982886  34.678555   34.607980\n",
       " 298616  78.316613  42.818219   25.434525\n",
       " 298618  84.360491  46.591848   37.909133\n",
       " \n",
       " [18569 rows x 3 columns],\n",
       " 'single_top':              mll    lead_pt  sublead_pt\n",
       " entry                                  \n",
       " 154    75.313851  31.020074    7.090479\n",
       " 420    73.330619  36.603496    9.136718\n",
       " 537    78.898357  84.510008   10.939663\n",
       " 668    71.233469  38.016438    8.916062\n",
       " 1397   79.551916  57.643223   18.144590\n",
       " 1759   95.730138  73.268383   23.727336\n",
       " 2239   96.640405  42.158047   22.278572\n",
       " 2379   73.891307  38.936520   10.673507}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_BDT = {} \n",
    "BDT_inputs = ['mll','lead_pt','sublead_pt'] # list of features for BDT\n",
    "for key in data: # loop over the different keys in the dictionary of dataframes\n",
    "    data_for_BDT[key] = data[key][BDT_inputs].copy()\n",
    "data_for_BDT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931c6ef4",
   "metadata": {},
   "source": [
    "Organising data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d6e378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one 2D array of shape (n_samples x n_features) \n",
    "\n",
    "all_MC = [] \n",
    "for key in data: \n",
    "    if key!='data': #Basically, all samples\n",
    "        all_MC.append(data_for_BDT[key])\n",
    "X = np.concatenate(all_MC) \n",
    "\n",
    "all_y = [] \n",
    "for key in data: \n",
    "    if key!='Zsignal' and key!='data': #Just background samples\n",
    "        all_y.append(np.zeros(data_for_BDT[key].shape[0])) # background events are labelled with 0\n",
    "all_y.append(np.ones(data_for_BDT['Zsignal'].shape[0])) # signal events are labelled with 1\n",
    "y = np.concatenate(all_y) # concatenate the list of lables into a single 1D array of labels, called y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac37527",
   "metadata": {},
   "source": [
    "Split for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f1f43892",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# make train and test sets\n",
    "X_train,X_test, y_train,y_test = train_test_split(X, y, \n",
    "                                                  test_size=0.33, \n",
    "                                                  random_state=492 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a9daf57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to fit BDT: 9.8s\n",
      "AdaBoostClassifier(algorithm='SAMME',\n",
      "                   base_estimator=DecisionTreeClassifier(max_depth=2),\n",
      "                   learning_rate=0.5, n_estimators=12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=2) # maximum depth of the tree\n",
    "bdt = AdaBoostClassifier(dt,\n",
    "                        algorithm='SAMME', # SAMME discrete boosting algorithm\n",
    "                        n_estimators=12, # max number of estimators at which boosting is terminated\n",
    "                        learning_rate=0.5) # shrinks the contribution of each classifier by learning_rate\n",
    "\n",
    "start = time.time() # time at start of BDT fit\n",
    "bdt.fit(X_train, y_train) # fit BDT to training set\n",
    "elapsed = time.time() - start # time after fitting BDT\n",
    "print(\"Time taken to fit BDT: \"+str(round(elapsed,1))+\"s\") # print total time taken to fit BDT\n",
    "print(bdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ea16507",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc10-opt/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc10-opt/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_101swan/x86_64-centos7-gcc10-opt/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  background       0.00      0.00      0.00      6033\n",
      "      signal       0.98      1.00      0.99    298250\n",
      "\n",
      "    accuracy                           0.98    304283\n",
      "   macro avg       0.49      0.50      0.49    304283\n",
      "weighted avg       0.96      0.98      0.97    304283\n",
      "\n",
      "Area under ROC curve for test data: 0.5034\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "y_predicted = bdt.predict(X_test) # get predicted y for test set\n",
    "print (classification_report(y_test, y_predicted,\n",
    "                            target_names=[\"background\", \"signal\"]))\n",
    "print (\"Area under ROC curve for test data: %.4f\"%(roc_auc_score(y_test,\n",
    "                                                    bdt.decision_function(X_test))) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
